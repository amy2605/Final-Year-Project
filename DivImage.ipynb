{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c37afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the path to your dataset directory\n",
    "#dataset_dir = 'path/to/dataset'\n",
    "dataset_path = 'C:/Users/Dell/Documents/AMIELIA FYP/TEST/dset/both'\n",
    "\n",
    "# Create directories for the training and validation sets\n",
    "train_path = 'C:/Users/Dell/Documents/AMIELIA FYP/TEST/dset/images/train'\n",
    "train_label = 'C:/Users/Dell/Documents/AMIELIA FYP/TEST/dset/labels/train'\n",
    "val_path = 'C:/Users/Dell/Documents/AMIELIA FYP/TEST/dset/images/val'\n",
    "val_label = 'C:/Users/Dell/Documents/AMIELIA FYP/TEST/dset/labels/val'\n",
    "\n",
    "\n",
    "# Set the percentage of images to use for validation (e.g. 20%)\n",
    "val_percent = 20\n",
    "\n",
    "# Get a list of all the image files in the dataset directory\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith(\".jpeg\")]\n",
    "\n",
    "# Shuffle the list of image files\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Calculate the number of validation images based on the val_percent\n",
    "num_val = int(len(image_files) * val_percent / 100)\n",
    "\n",
    "# Copy the first num_val images to the validation directory\n",
    "for i in range(num_val):\n",
    "    src_img = os.path.join(dataset_path, image_files[i])\n",
    "    dst_img = os.path.join(val_path, image_files[i])\n",
    "    shutil.copy(src_img, dst_img)\n",
    "    \n",
    "    # Copy the corresponding annotation file if it exists\n",
    "    ann_file = image_files[i].replace(\".jpeg\", \".txt\")\n",
    "    if os.path.isfile(os.path.join(dataset_path, ann_file)):\n",
    "        src_ann = os.path.join(dataset_path, ann_file)\n",
    "        dst_ann = os.path.join(val_label, ann_file)\n",
    "        shutil.copy(src_ann, dst_ann)\n",
    "\n",
    "# Copy the remaining images to the training directory\n",
    "for i in range(num_val, len(image_files)):\n",
    "    src_img = os.path.join(dataset_path, image_files[i])\n",
    "    dst_img = os.path.join(train_path, image_files[i])\n",
    "    shutil.copy(src_img, dst_img)\n",
    "    \n",
    "    # Copy the corresponding annotation file if it exists\n",
    "    ann_file = image_files[i].replace(\".jpeg\", \".txt\")\n",
    "    if os.path.isfile(os.path.join(dataset_path, ann_file)):\n",
    "        src_ann = os.path.join(dataset_path, ann_file)\n",
    "        dst_ann = os.path.join(train_label, ann_file)\n",
    "        shutil.copy(src_ann, dst_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369ea2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
